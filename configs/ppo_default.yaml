# PPO Training Configuration for PiDog

algorithm: ppo

# Training parameters
total_timesteps: 1000000
n_envs: 4
save_freq: 10000
eval_freq: 5000
eval_episodes: 5

# PPO hyperparameters
learning_rate: 0.0003
n_steps: 2048
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01
vf_coef: 0.5
max_grad_norm: 0.5

# Environment
env_name: PiDog-v0
max_episode_steps: 1000

# System
seed: 42
device: auto

# Output
output_dir: outputs
experiment_name: null  # Auto-generated if null
